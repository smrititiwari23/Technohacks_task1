# -*- coding: utf-8 -*-
"""fraud.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1VL-rHulTkLZUtCZl6py7fB6FFBa61mQn
"""

# Importing libraries
import numpy as np  # Importing the NumPy library for numerical computing
import pandas as pd  # Importing the Pandas library for data manipulation and analysis

import matplotlib.pyplot as plt  # Importing the Matplotlib library for data visualization
import seaborn as sns  # Importing the Seaborn library for advanced data visualization
pd.set_option('display.max_columns', None)  # Setting an option to display all columns in the DataFrame

from google.colab import files


uploaded = files.upload()

# Importing dataset
dataset = pd.read_csv("creditcard.csv")
# Reading the CSV file into a DataFrame named 'dataset'

dataset.head()

dataset.info()

dataset.isnull().values.any()

dataset['Class'].unique()

# Visualizing the amount of Fraud and Non Fraud transactions

## The percentage of Fraud and Non Fraud transactions chart

# Define the labels for the pie chart
labels = 'Not Fraud', 'Fraud'

# Calculate the count of Fraud and Non Fraud transactions in the dataset
sizes = [dataset.Class[dataset['Class']==0].count(), dataset.Class[dataset['Class']==1].count()]

# Create a new figure and axis for the pie chart
fig1, ax1 = plt.subplots(figsize=(10, 6))

# Plot the pie chart with the calculated sizes and labels
ax1.pie(sizes, labels=labels, autopct='%1.2f%%', shadow=False, startangle=120)

# Set the axis equal to make the pie chart a perfect circle
ax1.axis('equal')

# Set the title of the pie chart with added distance (pad) between the title and the chart
title = "The Percentage of Fraud and Non Fraud transactions"
plt.title(title, size=16, pad=20)  # You can change the pad value to adjust the distance

# Show the pie chart
plt.show()

sns.set(style="whitegrid")

# Create the countplot
ax = sns.countplot(x='Class', data=dataset, order=[0, 1], label='Count', palette='pastel')

# Calculate the counts of E-signed and Not E-signed customers
counts = dataset['Class'].value_counts()

# Add text annotations for the counts
for i, count in enumerate(counts):
    ax.text(i, count, str(count), ha='center', va='bottom', fontsize=12)

# Set the title
title = "The Amount of Fraud and Non Fraud Transactions"
ax.set_title(title, size=16)
plt.title(title, size=16, pad=20)
# Show the plot
plt.show()

dataset_2 = dataset.drop(columns=['Class'])

# Calculate the correlation between each column in 'dataset_2' and the 'Class' column in the original dataset
correlation_with_class = dataset_2.corrwith(dataset['Class'])

# Create a bar plot to visualize the correlation values with the 'Class' column
# Set the size of the figure to 16 inches (width) by 8 inches (height)
# Show grid lines in the plot for better readability
correlation_with_class.plot.bar(figsize=(16, 8), grid=True)

# Set appropriate labels and titles for the plot
plt.xlabel("Features")  # Label for the x-axis (features)
plt.ylabel("Correlation with Class")  # Label for the y-axis (correlation values)
plt.title("Correlation of Features with Class")  # Set the title for the bar plot

# Show the plot
plt.show()

corr = dataset.corr()

# Set the size of the heatmap figure
plt.figure(figsize=(30, 24))

# Create the heatmap using seaborn
# 'annot=True' displays the correlation values on the heatmap
# 'cmap='coolwarm'' sets the color map for the heatmap
# 'fmt='.2f'' sets the format of the displayed correlation values to have two decimal places
sns.heatmap(corr, annot=True, cmap='coolwarm', fmt='.2f')

# Set the title for the heatmap
plt.title("Correlation Heatmap", fontsize=24)

# Show the heatmap
plt.show()

x = dataset.drop(columns=['Class']) # X contains all columns except 'Class'
y = dataset['Class']

from sklearn.model_selection import train_test_split
x_train, x_test, y_train, y_test = train_test_split(x, y, test_size = 0.2, random_state=0)

from sklearn.preprocessing import StandardScaler

sc = StandardScaler()

x_train = sc.fit_transform(x_train)
x_test = sc.transform(x_test)

# Importing the logistic regression classifier
from sklearn.linear_model import LogisticRegression

# Creating an instance of the logistic regression classifier
# Setting the random_state to ensure reproducibility of results
classifier_lr = LogisticRegression(random_state=0)

classifier_lr.fit(x_train, y_train)

y_pred = classifier_lr.predict(x_test)

from sklearn.metrics import accuracy_score, confusion_matrix, f1_score, precision_score, recall_score

# Calculate accuracy using the predicted and true target values (y_pred and y_test)
acc = accuracy_score(y_test, y_pred)

# Calculate F1 score using the predicted and true target values (y_pred and y_test)
f1 = f1_score(y_test, y_pred)

# Calculate precision score using the predicted and true target values (y_pred and y_test)
prec = precision_score(y_test, y_pred)

# Calculate recall score using the predicted and true target values (y_pred and y_test)
rec = recall_score(y_test, y_pred)

results = pd.DataFrame([['LogisticRegression', acc, f1, prec, rec]],
                       columns = ["Model", "accuracy", "f1", "precision", "recall"])

results

cm = confusion_matrix(y_test, y_pred)
print(cm)